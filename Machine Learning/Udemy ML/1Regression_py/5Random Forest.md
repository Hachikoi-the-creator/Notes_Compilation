Assemble learning:
Pick one or multiple algorithm multiple times, achieving more of what could be done whit just one.

<h4>How it works?</h4>

Instead of taking into account all your data set, the model picks a random data and builds a decision tree to reach it
Then you choose the number of trees you want (fixing how specific you want the model to be)
To make predictions, the model predicts Y whit all the trees and returns the average

Thus makes cluster the other way around  Decision tree does

Lovely example of the competition where I won the washer/dryer, the best way to win that game is to ask to say 100 people and then just take the average of their responses, thus you'll be the one whit the higher like hood of winning!